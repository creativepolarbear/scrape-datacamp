# Python modularity in the wild

In the slides, we covered 3 ways that you can write modular code with
Python: **packages**, **classes**, and **methods**. For reference, you
can see the example code we reviewed below.

    # Import the pandas PACKAGE
    import pandas as pd

    # Create some example data
    data = {'x': [1, 2, 3, 4], 
            'y': [20.1, 62.5, 34.8, 42.7]}

    # Create a dataframe CLASS object
    df = pd.DataFrame(data)

    # Use the plot METHOD
    df.plot('x', 'y')

In this exercise, you'll utilize a **class** & a **method** from the
popular **package** `numpy`.

**Instructions**

- Complete the `import` statement to load the `numpy` **package**.
- Use `numpy`'s `array` **class** to define `arr`.
- Use `arr`'s `sort` **method** to sort the `numpy` array.

**Answer**

# Leveraging documentation

When writing code for Data Science, it's inevitable that you'll need to
install and use someone else's code. You'll quickly learn that using
someone else's code is much more pleasant when they use good software
engineering practices. In particular, good documentation makes the right
way to call a function obvious. In this exercise you'll use python's
`help()` method to view a function's documentation so you can determine
how to correctly call a new method.

The list `words` has been loaded in your session.

**Instructions**

- View the documentation of the `Counter.most_common` method using the
  `help()` function. Note, you need to run the `import` statement before
  completing this step.

**Answer**

# Using pycodestyle

We saw earlier that pycodestyle can be run from the command line to
check a file for PEP 8 compliance. Sometimes it's useful to run this
kind of check from a Python script.

In this exercise, you'll use `pycodestyle`'s `StyleGuide` class to check
multiple files for PEP 8 compliance. Both files accomplish the same
task, but they differ greatly in formatting and readability. You can
view the contents of the files by following their links below.

**Instructions**

- Import the `pycodestyle` package.
- Create an instance of `StyleGuide` named `style_checker`.
- There are two files that we'll be checking; they're named
  [`'nay_pep8.py'`](https://assets.datacamp.com/production/repositories/3557/datasets/c7ac87a2c9614dfe34bfaf1d21fcab27c41ef6dc/nay_pep8.py)
  and
  [`'yay_pep8.py'`](https://assets.datacamp.com/production/repositories/3557/datasets/de962c1559a15ef9ef5a3d5da5ea7a02890fa3f1/yay_pep8.py).
  Pass a list containing these file names to our `style_checker`'s
  `check_files` method.
- `print()` the results of our style check to the console. Make sure to
  read the output!

**Answer**

# Conforming to PEP 8

As we've covered, there are tools available to check if your code
conforms to the PEP 8 guidelines. One possible way to stay compliant is
to use an IDE that warns you when you accidentally stray from the style
guide. Another way to check code is to use the `pycodestyle` package.

The results below show the output of running `pycodestyle` check against
the code shown in your editor. The leading number in each line shows how
many occurrences there were of that particular violation.

    my_script.py:2:2:  E225 missing whitespace around operator
    my_script.py:2:7:  E231 missing whitespace after ','
    my_script.py:2:9:  E231 missing whitespace after ','
    my_script.py:5:7:  E201 whitespace after '('
    my_script.py:5:11: E202 whitespace before ')'

**Instructions**

- Leverage the output of `pycodestyle` to edit the code to be compliant
  with PEP 8.

**Answer**

# PEP 8 in documentation

So far we've focused on how PEP 8 affects functional pieces of code.
There are also rules to help make comments and documentation more
readable. In this exercise, you'll be fixing various types of comments
to be PEP 8 compliant.

The result of a `pycodestyle` style check on the code can be seen below.

    my_script.py:2:15: E261 at least two spaces before inline comment
    my_script.py:5:16: E262 inline comment should start with '# '
    my_script.py:11:1: E265 block comment should start with '# '
    my_script.py:13:2: E114 indentation is not a multiple of four (comment)
    my_script.py:13:2: E116 unexpected indentation (comment)

**Instructions**

- Leverage the output of `pycodestyle` to edit the code's comments to be
  compliant with PEP 8.

**Answer**

# Naming packages

We covered the PEP 8 guidelines for naming packages. In this exercise,
you'll use that knowledge to identify a package following the
requirements.

For additional reference, you can view the [PEP 8 section on package
naming
here](https://www.python.org/dev/peps/pep-0008/#package-and-module-name)

**Instructions**

- The possible package names to `import` are the following:
  `text_analyzer`, `textAnalyzer`, `TextAnalyzer`, &
  `__text_analyzer__`.
- `import` the package from the list above that follows the PEP 8 naming
  conventions.

**Answer**

# Recognizing packages

The structure of your directory tree is printed below. You'll be working
in the file `my_script.py` that you can see in the tree.

    recognizing_packages
    ├── MY_PACKAGE
    │&nbsp;&nbsp; └── _init_.py
    ├── package
    │&nbsp;&nbsp; └── __init__.py
    ├── package_py
    │&nbsp;&nbsp; └── __init__
    │&nbsp;&nbsp;     └── __init__.py
    ├── py_package
    │&nbsp;&nbsp; └── __init__.py
    ├── pyackage
    │&nbsp;&nbsp; └── init.py
    └── my_script.py

**Instructions**

- Use the information from the context to identify the packages in the
  directory that follow the minimal structure.
- `import` the two packages that follow the minimal package
  requirements.
- Use `help()` to print information about each imported package.

**Answer**

# Adding functionality to your package

Thanks to your work before, you already have a skeleton for your python
package. In this exercise, you will work to define the functions needed
for a text analysis of word usage.

In the file `counter_utils.py`, you will write 2 functions to be a part
of your package: `plot_counter` and `sum_counters`. The structure of
your package can be seen in the tree below. For the coding portions of
this exercise, you will be working in the file `counter_utils.py`.

    text_analyzer
    ├── __init__.py
    └── counter_utils.py

**Instructions**

- Define `top_items` using `plot_counter`'s inputs.

**Answer**

# Using your package's new functionality

You've now created some great functionality for text analysis to your
package. In this exercise, you'll leverage your package to analyze some
tweets written by DataCamp & DataCamp users.

The object `word_counts` is loaded into your environment. It contains a
list of `Counter` objects that contain word counts from a sample of
DataCamp tweets.

The structure you've created can be seen in the tree below. You'll be
working in `my_script.py`.

    working_dir
    ├── text_analyzer
    │    ├── __init__.py
    │    ├── counter_utils.py
    └── my_script.py

**Instructions**

- `import` your `text_analyzer` at the top of the script.
- Use the `sum_counters()` function from `text_analyzer` to aggregate
  all the `Counter`s in `word_counts`.
- Use the `plot_counter()` function from `text_analyzer` to visualize
  the tweet's most used words while tweeting.

**Answer**

# Writing requirements.txt

We covered how having a `requirements.txt` file can help your package be
more portable by allowing your users to easily recreate its intended
environment. In this exercise, you will be writing the contents of a
requirements file to a python variable.

*Note, in practice, the code you write in this exercise would be written
to it's own `txt` file instead of a variable in your python session.*

**Instructions**

- Write the requirement for `matplotlib` with at least version `3.0.0`
  or above.
- Write the requirement for `numpy` version 1.15.4 exactly.
- Write the requirement for `pandas` with at most version 0.22.0.
- Write a non-version specific requirement for `pycodestyle`

**Answer**

# Creating setup.py

In order to make your package installable by `pip` you need to create a
`setup.py` file. In this exercise you will create this file for the
`text_analyzer` package you've been building.

**Instructions**

- `import` the needed function, `setup`, from the `setuptools` package.
- Complete the `name` & `packages` arguments; keep in mind your package
  is located in a directory named `text_analyzer`.
- List yourself as the `author`.

**Answer**

# Listing requirements in setup.py

We created a setup.py file earlier, but we forgot to list our dependency
on `matplotlib` in the `install_requires` argument. In this exercise you
will practice listing your version specific dependencies by correcting
the `setup.py` you previously wrote for your `text_analyzer` package.

**Instructions**

- `import` the needed function, `setup`, from the `setuptools` package.
- List yourself as the `author`.
- Specify your `install_requires` to require `matplotlib` version
  `3.0.0` or above.

**Answer**

# Writing a class for your package

We've covered how classes can be written in Python. In this exercise,
you'll be creating the beginnings of a `Document` class that will be a
foundation for text analysis in your package. Once the class is written
you will modify your package's `__init__.py` file to make it easily
accessible by your users.

Below is the structure of where you'll be working.

    working_dir
    ├── text_analyzer
    │    ├── __init__.py
    │    ├── counter_utils.py
    │    ├── document.py
    └── my_script.py

**Instructions**

- You are working in `document.py`.
- Finish the `def` statement that will create a new `Document` instance
  when a user calls `Document()`.
- Use your knowledge of PEP 8 conventions to complete the definition of
  the newly named class method.

**Answer**

# Using your package's class

You just wrote the beginnings of a `Document` class that you'll build
upon to perform text analysis. In this exercise, you'll test out its
current functionality of storing text.

Below is the document tree that you've built up so far when developing
your package. You'll be working in `my_script.py`.

    working_dir
    ├── text_analyzer
    │    ├── __init__.py
    │    ├── counter_utils.py
    │    ├── document.py
    └── my_script.py

**Instructions**

- `import` your `text_analyzer` package.
- Create an instance of `Document` with the `datacamp_tweet` variable
  that's been loaded into your session.
- Print the contents of the `text` attribute of your newly created
  `Document` instance.

**Answer**

# Writing a non-public method

In the lesson, we covered how to add functionality to classes using
non-public methods. By defining methods as non-public you're signifying
to the user that the method is only to be used inside the package.

In this exercise, you will define a non-public method that will be
leveraged by your class to count words.

**Instructions**

- `Counter` from `collections` has been loaded into your environment, as
  well as the function `tokenize()`.
- Add a method named `count_words` **as a non-public method**.
- Give your non-public method the functionality to count the contents
  `tokens` attribute using `Counter()`.
- Utilize your new function in the `__init__` method.

**Answer**

# Using your class's functionality

You've now added additional functionality to your `Document` class's
`__init__` method that automatically processes text for your users. In
this exercise, you'll act as one of those users to see the benefits of
your hard work.

The `Document` class (copied below) has been loaded into your
environment (complete with your new updates).

    class Document:
      def __init__(self, text):
        self.text = text
        # pre tokenize the document with non-public tokenize method
        self.tokens = self._tokenize()
        # pre tokenize the document with non-public count_words
        self.word_counts = self._count_words()

      def _tokenize(self):
        return tokenize(self.text)

      # non-public method to tally document's word counts with Counter
      def _count_words(self):
        return Counter(self.tokens)

**Instructions**

- Create a new `Document` instance from the `datacamp_tweets` data set
  loaded into your environment. The `datacamp_tweets` object is a single
  string containing hundreds of tweets written by DataCamp & DataCamp
  users.
- Print the first 5 `tokens` from `datacamp_doc`.
- Print the top 5 most common words that were calculated by the
  non-public `_count_words()` method automatically in the
  `Document.__init__` method.

**Answer**

# Using inheritance to create a class

You've previously written a `Document` class for text analysis, but your
NLP project will now have a focus on Social Media data. Your general
`Document` class might be useful later so it's best not destroy it while
your focus shifts to tweets.

Instead of copy-pasting the already written functionality, you will use
the principles of 'DRY' and inheritance to quickly create your new
`SocialMedia` class.

**Instructions**

- `Document` has been preloaded in the session.
- Complete the `class` statement to create a `SocialMedia` class that
  inherits from `Document`.
- Define `SocialMedia`'s `__init__()` method that initializes a
  `Document`.

**Answer**

# Adding functionality to a child class

You've just written a `SocialMedia` class that inherits functionality
from `Document`. As of now, the `SocialMedia` class doesn't have any
functionality different from `Document`. In this exercise, you will
build features into `SocialMedia` to specialize it for use with Social
Media data.

For reference, the definition of `Document` can be seen below.

    class Document:
        # Initialize a new Document instance
        def __init__(self, text):
            self.text = text
            # Pre tokenize the document with non-public tokenize method
            self.tokens = self._tokenize()
            # Pre tokenize the document with non-public count_words
            self.word_counts = self._count_words()

        def _tokenize(self):
            return tokenize(self.text)

        # Non-public method to tally document's word counts
        def _count_words(self):
            # Use collections.Counter to count the document's tokens
            return Counter(self.tokens)

**Instructions**

- The function `filter_word_counts()` has been loaded in your session.
  Use `help()` to see its proper usage.
- Finish the `_count_hashtags` method using `filter_word_counts()` so
  that only words_counts starting with `#` remain.

**Answer**

# Using your child class

Thanks to the power of inheritance you were able to create a
feature-rich, `SocialMedia` class based on its parent, `Document`. Let's
see some of these features in action.

Below is the full definition of `SocialMedia` for reference.
Additionally, `SocialMedia` has been added to `__init__.py` for ease of
use.

    class SocialMedia(Document):
        def __init__(self, text):
            Document.__init__(self, text)
            self.hashtag_counts = self._count_hashtags()
            self.mention_counts = self._count_mentions()

        def _count_hashtags(self):
            # Filter attribute so only words starting with '#' remain
            return filter_word_counts(self.word_counts, first_char='#')      

        def _count_mentions(self):
            # Filter attribute so only words starting with '@' remain
            return filter_word_counts(self.word_counts, first_char='@')

**Instructions**

- `import` your `text_analyzer` custom package.
- Define `dc_tweets` as an instance of `SocialMedia` with the preloaded
  `datacamp_tweets` object as the `text`.
- `print` the `5` `most_common` mentioned users in the data using the
  appropriate `dc_tweets` attribute.
- Use `text_analyzer`'s `plot_counter()` method to plot the most used
  hashtags in the data using the appropriate `dc_tweets` attribute.

**Answer**

# Exploring with dir and help

A new method has been added to the `Document` class. The method is a
convenience wrapper around the `plot_counter()` function you wrote in an
earlier exercise. In this exercise, you'll use `dir()` and `help()` to
identify how to utilize the new method.

**Instructions**

- `import` the `text_analyzer` package.
- Define `my_doc` as an instance of `Document` with the text stored in
  `datacamp_tweets`. `datacamp_tweets` has been pre-loaded in your
  environment.

**Answer**

# Creating a grandchild class

In this exercise you will be using inheritance to create a `Tweet` class
from your `SocialMedia` class. This new grandchild class of `Document`
will be able to tackle Twitter specific details such as retweets.

**Instructions**

- Complete the `class` statement so that `Tweets` inherits from
  `SocialMedia`. `SocialMedia` has already been loaded in your
  environment.
- Use `super()` to call the `__init__` method of the parent class.
- Define `retweet_text`. Use `help()` to complete the call to
  `filter_lines` with the correct parameter name. `filter_lines` has
  already been loaded in your environment.
- `return` `retweet_text` from `_process_retweets` as an instance of
  `SocialMedia`.

**Answer**

# Using inherited methods

You've now defined a `Tweets` class that's inherited methods from both
`Document` and `SocialMedia`. In this exercise, you'll use inherited
methods to visualize text from both tweets and retweets.

*Be aware that this is real data from Twitter and as such there is
always a risk that it may contain profanity or other offensive content
(in this exercise, and any following exercises that also use real
Twitter data).*

**Instructions**

- `import` your `text_analyzer` package.
- Define `my_tweets` as an instance of `Tweets` using the
  `datacamp_tweets` data that has been pre-loaded into your environment.

**Answer**

# Identifying good comments

We learned about what characteristics make a 'good' comment. In this
exercise, you'll apply this knowledge to identify a function that
utilizes comment best practices.

**Instructions**

- `print` the `text` variable that has been pre-loaded into your
  environment.
- `print` the result of calling the function with more useful commenting
  on `text`.

**Answer**

# Identifying proper docstrings

We covered how to write fully-fledged docstrings. Before writing one of
your own, this exercise will help you practice by having you identify a
properly formatted docstring.

In this exercise, you'll be using the functions `goldilocks()`,
`rapunzel()`, `mary()`, and `sleeping_beauty()` which have been loaded
in your environment.

**Instructions**

- Run `help()` on each of the 4 functions to view their docstrings.

**Answer**

# Writing docstrings

We just learned some about the benefits of docstrings. In this exercise,
you will practice writing docstrings that can be utilized by a
documentation generator like Sphinx.

Note that your docstring submission must match the solution *exactly*.
If you find yourself getting it wrong several times, it may be a good
idea to refresh the sample code and start over.

**Instructions**

- Complete the portions of the docstring that document the parameters.
- Complete the portion of the docstring describing the return value.
- Complete the example function usage in the docstring.

**Answer**

# Using good function names

A good function name can go a long way for both user and maintainer
understanding. A good function name is descriptive and describes what a
function does. In this exercise, you'll choose a name for a function
that will help aid in its readability when used.

**Instructions**

- The `math` module has been pre-loaded into your environment to be able
  to use its `sqrt` function.
- Give function the best possible name from the following options:
  `do_stuff`, `hypotenuse_length`,
  `square_root_of_leg_a_squared_plus_leg_b_squared`,
  `pythagorean_theorem`.
- Complete the docstring's example with the function's name.
- `print` the result of using the newly named function to find the
  length of the hypotenuse for a right triangle with legs of length `6`
  & `8`.

**Answer**

# Using good variable names

Just like functions, descriptive variable names can make your code much
more readable. In this exercise, you'll write some code using good
variable naming practices.

There's not always a clear best name for a variable. The exercise has
been written to try and make a clear *best* choice from the provided
options.

**Instructions**

- Choose the best variable name to hold the sample of pupil diameter
  measurements in millimeters from the following choices: `d`,
  `diameter`, `pupil_diameter`, or `pupil_diameter_in_millimeters`.
- Take the `mean` of the measurements and assign it to a variable.
  Choose the best variable name to hold this mean from the following
  options: `m`, `mean`, `mean_diameter`, or
  `mean_pupil_diameter_in_millimeters`.
- Print the resulting average pupil diameter.

**Answer**

# Refactoring for readability

Refactoring longer functions into smaller units can help with both
readability and modularity. In this exercise, you will refactor a
function into smaller units. The function you will be refactoring is
shown below. Note, in the exercise, you won't be using docstrings for
the sake of space; in a real application, you should include
documentation!

    def polygon_area(n_sides, side_len):
        """Find the area of a regular polygon

        :param n_sides: number of sides
        :param side_len: length of polygon sides
        :return: area of polygon

        >>> round(polygon_area(4, 5))
        25
        """
        perimeter = n_sides * side_len

        apothem_denominator = 2 * math.tan(math.pi / n_sides)
        apothem = side_len / apothem_denominator

        return perimeter * apothem / 2

**Instructions**

- Move the logic for calculating the `perimeter` into the
  `polygon_perimeter` function.
- Complete the definition of the `polygon_apothem` function, by moving
  the logic seen in the context. The `math` module has already been
  imported for you.
- Utilize the new unit functions to complete the definition of
  `polygon_area`.
- Use the more unitized `polygon_area` to calculate the area of a
  regular hexagon with legs of size 10.

**Answer**

# Using doctest

We just learned about doctest, which, if you're writing full docstrings
with examples, is a simple way to minimally test your functions. In this
exercise, you'll get some hands-on practice testing and debugging with
doctest.

The following have all be pre-loaded in your environment: `doctest`,
`Counter`, and `text_analyzer`.

Note that your docstring submission must match the solution *exactly*.
If you find yourself getting it wrong several times, it may be a good
idea to refresh the sample code and start over.

**Instructions**

- Complete the input code of the example in the docstring for
  `sum_counters`.
- Complete the docstring example by filling in the expected output.
- Run the `testmod` function from `doctest` to test your function's
  example code.

**Answer**

# Using pytest

`doctest` is a great tool, but it's not nearly as powerful as `pytest`.
In this exercise, you'll write tests for your `SocialMedia` class using
the `pytest` framework.

**InstructionsAnswer**

# Documenting classes for Sphinx

`sphinx` is a great tool for rendering documentation as HTML. In this
exercise, you'll write a docstring for a class that can be taken
advantage of by `sphinx`.

Note that your docstring submission must match the solution *exactly*.
If you find yourself getting it wrong several times, it may be a good
idea to refresh the sample code and start over.

**Instructions**

- `import` the `Document` class `from` the `text_analyzer` package for
  use in the class definition.
- Complete the line of the docstring dealing with the parameters of the
  `__init__` method.
- Complete the docstring by filling out the documentation for the
  attributes or 'instance variables' of the `SocialMedia` class.

**Answer**
